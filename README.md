# Aws_Projects
In this repo there will be all aws files are available

By , Abhishek Shelar
 AWS NOTES
 Cloud
• Cloud computing is like renting space on a powerful 
computer over the internet. 
• Instead of owning and managing your own 
hardware and software, you can use resources 
provided by cloud service providers. 
• These resources include storage, processing 
power, and software applications. 
• Cloud computing allows you to access and manage 
your data and programs from anywhere with an 
internet connection, making it convenient and 
flexible. 
• It's like having a virtual office or storage space that 
you can access anytime , anywhere.
• Here's a real-life example:
Imagine you're a photographer and you take lots of 
pictures. Instead of storing all those photos on your 
own computer, which might run out of space, you 
can upload them to a cloud storage service like 
Google Photos or iCloud. These services store your 
photos on their servers in the cloud. Now, you can 
By , Abhishek Shelar
access your photos from anywhere with an internet 
connection.
 Why Cloud?
• Cloud computing is used for various reasons, 
primarily because it offers flexibility, scalability, costeffectiveness, and accessibility. 
• Cloud computing involves the delivery of computing 
services—like servers, storage, databases, 
networking, software, and more—over the internet 
("the cloud") to offer faster innovation, flexible 
resources, and economies of scale. Instead of 
owning physical hardware or managing software, 
users can access resources as needed from cloud 
service providers on a pay-as-you-go basis
How cloud is used?
• Cloud computing is like renting space on powerful 
internet-connected computers to store data or run 
programs. It's used widely nowadays because it's 
convenient, cost-effective, and accessible from 
anywhere.
• Real-Life Example:
 Think of streaming services like Netflix or Spotify. 
Instead of storing movies or songs on your device, 
they're stored in the cloud. When you want to watch a 
movie or listen to music, you stream it over the 
By , Abhishek Shelar
internet, accessing it from the cloud without needing 
to download the entire file. This makes it easy to enjoy 
your favorite entertainment from any device with an 
internet connection.
 Types Of Cloud
• Public Cloud:
Public cloud services are available to the 
general public over the internet. AWS offers a 
comprehensive range of public cloud services 
accessible to anyone, from individuals to 
enterprises. Users can access and use these 
services on a pay-as-you-go basis
• Private Cloud:
 Private cloud services are dedicated to a 
single organization and are not shared with other 
organizations. In AWS, customers can create a 
private cloud environment using services like 
Amazon Virtual Private Cloud (VPC) to establish 
isolated sections of the AWS cloud where they have 
full control over resources and networking
• Hybrid Cloud:
 Hybrid cloud environments combine elements 
of both public and private clouds. Organizations 
By , Abhishek Shelar
may use a mix of on-premises infrastructure, private 
cloud resources, and public cloud services. AWS 
services, and AWS Direct Connect for private 
network connections to AWS.
• Community Cloud:
 Community cloud services are shared by 
several organizations with similar requirements, 
such as compliance or security standards. While 
AWS primarily focuses on public and private cloud 
offerings, organizations can implement community 
cloud environments using AWS services and 
features, tailored to meet the specific needs of a 
community 
 
 LINUX
• Linux is a powerful and flexible family of operating 
system that are free to use and share. It was 
created by a person named Linus Torvalds in 1991. 
• Linux has become the largest open source software 
project in the world.
• What’s cool is that anyone can see how the system 
works because its source code is open for everyone 
to explore and modify. 
By , Abhishek Shelar
• This openness encourages people from all over the 
world to work together and make Linux better and 
better.
• It’s known for being efficient, meaning it can do a 
lot of tasks quickly, and it’s also cost-effective.Linux 
has grown into a stable and safe system used in 
many different things, like computers, smartphones, 
and big supercomputers.
Linux components and terminology 
 The Linux OS system incorporates several different 
components including:
• Bootloader
 A bootloader is responsible for managing the boot process 
of the computer and for starting the Linux Kernel.
• Kernel
The core of the Linux system,the kernel handles network 
access,schedules processes or applications.The Linux 
software that interact directly with the computer hardware. 
• Init system
The first process to run once the kernel is loaded.A 
process is an instance of a program running on a 
computer.Init can be configured to start specific processes 
at system initalization.
By , Abhishek Shelar
• Daemons
This is program that runs in background,handling request 
for a service.
• Graphical Server
This is software that controls how graphics are displayed 
on a computer.Without a graphical server,users can only 
interact with the Linux system through a command line 
interface.
Popular Linux distributors:
• Ubuntu
• Fedora Linux
• Suse Linux
• Mageia
• BlackArch
Difference between Linux and Windows
By , Abhishek Shelar
 Monolithic Kernel and Microlithic Kernel
Why Linux Os is more suitable?
By , Abhishek Shelar
• Linux is an operating system, similar to Windows, 
but it's free and open-source. This means anyone 
can use, modify, and share it. It's known for being 
stable, secure, and customizable.
 LINUX COMMANDS
• ls : List of files and directories in the current 
directory.
• pwd : Print the current working directory.
• cd : Change the current directory.
• touch : Create an empty file.
• mkdir : Create a new directory.
• rmdir : Remove an empty directory.
• find : Search for files and directories.
• chmod : Change file permissions.
• rm : Remove files or directories.
• cp : Copy files or directories.
• mv : Move or rename files and directories.
• cat : Concatenate and display file content.
• less : View file content one screen at a time.
• more : View file content page by page.
• head : Display the beginning of a file.
• tail : Display the end of a file.
By , Abhishek Shelar
• grep : Search for text using patterns.
• chmod : Change file permissions or modify file 
permissions.
• chown : Change file ownership.
• ps : Display information about running processes.
• kill : Terminate processes.
• top : Monitor system resources and processes.
• df : Display disk space usage.
• du : Show directory space usage.
• tar : Archive and compress files.
• gzip : Compress files.
• gunzip : Decompress files.
• wget : Download files from the internet.
• curl : Transfer data with URLs.
• ping : Send ICMP echo requests to a host.
• ifconfig : Display ip address
• passwd : Change user password.
• useradd : Create new user
• userdel : Delete a user account.
• su : Switch user or become superuser.
• sudo : Execute commands as another user (usually 
the superuser).
• who : Display information about logged-in users.
By , Abhishek Shelar
• date : Display or set the system date and time.
• shutdown : Shutdown or reboot the system.
• exit : Exit the current shell session.
• history : Display command history.
• man : Display the manual pages for commands.
• info : Display command information.
• nano : A simple text editor.
• vim : A powerful text editor.
• emacs : Another text editor, popular among 
developers.
• htop : Interactive process viewer.
• fdisk : A command-line disk partitioning tool for 
managing disk partitions.
• resized : There's no standard Linux command 
named "resized." It might be a typo or a custom 
script
• ssh : Securely connect to remote systems.
• scp : Securely copy files between hosts.
• ssh-keygen : Generate SSH key pairs.
• Init 0 :Shut down the sysytem
• Init 6 :Restart the system
• | (pipe sign) : combine two commands
• egrep : Search two or more patterns
By , Abhishek Shelar
 Vi Editor commands
• $ vi <filename> — Open or edit a file.
• i — Switch to Insert mode.
• Esc — Switch to Command mode.
• :w — Save and continue editing.
• :wq or ZZ — Save and quit/exit vi.
• :q! — Quit vi and do not save changes.
• yy — Yank (copy) a line of text.
• p — Paste a line of yanked text below the current line.
• o — Open a new line under the current line.
• O — Open a new line above the current line.
• A — Append to the end of the line.
• a — Append after the cursor’s current position.
• I — Insert text at the beginning of the current line.
• b — Go to the beginning of the word.
• e — Go to the end of the word.
• x — Delete a single character.
• dd — Delete an entire line.
• Xdd — Delete X number of lines.
• Xyy — Yank X number of lines.
• G — Go to the last line in a file.
• XG — Go to line X in a file.
• gg — Go to the first line in a file.
• :num — Display the current line’s line number.
• h — Move left one character.
• j — Move down one line.
• k — Move up one line.
• l — Move right one character.
 File compression commands
• c : Create a new archive
By , Abhishek Shelar
• z : Use gzip compression
• v : Provide verbose output
• f : Archive file name 
• x : Extract from a compressed file
 AWS
• AWS stands for Amazon Web Services. It's a cloud 
computing platform offered by Amazon that 
provides a wide range of services such as 
computing power, storage, databases, networking,
machine learning, analytics, and more, all delivered 
over the internet on a pay-as-you-go basis.
• It is a collection of cloud computing services 
provided by Amazon. Essentially, it's like renting 
space on Amazon's powerful computers (servers) to
store your data, run your applications, or perform 
other computing tasks over the internet.
• Many companies use AWS because it's reliable, 
scalable, and offers a wide range of services to 
meet various needs.
Delivering Model of AWS and Cloud Computing
1. IaaS (Infrastructure as a Service):
IaaS is also known as Hardware as a Service.It is a 
computing infrastructure managed over the 
internet.The main advantage of using IaaS is that it 
By , Abhishek Shelar
helps users to avoid the cost and complexity of 
purchasing and managing the physical servers.
Characterstics of IaaS:
• Resources are available as a service
• Services are highly scalable
• Dynamic and flexible
• GUI and API-based access
• Automated administrative tasks
2. PaaS (Platform as a Service):
PaaS cloud computing platform is created for the 
programmer to develop,test,run and manage the 
applications.
Characterstics of PaaS:
• Accessible to various users via the same 
development application.
• Integrates to various users via the same 
development application.
• Support multiple languages and frameworks.
• Provide an ability to “Auto-scale”.
By , Abhishek Shelar
3. SaaS (Software as a Service):
SaaS is also known as “on-demand software”.It is a 
software in which the applications are hosted by a 
cloud service provider.Users can access these 
applications with the help of internet connection and 
web browser.
Characterstics of SaaS:
• Managed from central location.
• Hosted on remote server.
• Accessible over the internet.
• The services are purchased on the pay-as-per-use 
basis
 
 
By , Abhishek Shelar
 Benefits of AWS
• Scalability: AWS allows you to easily scale your 
resources up or down based on your needs. If your 
website suddenly gets a lot of visitors, AWS can 
handle the increased traffic without crashing.
• Cost-effectiveness: Instead of buying and 
maintaining expensive hardware, you pay only for 
the computing power and resources you use. It's 
like paying for electricity - you only pay for what you 
consume.
• Reliability: AWS operates data centers all around 
the world, ensuring high availability and reliability. 
It's like having a backup generator - even if one 
data center goes down, your services can continue 
running from another location.
• Flexibility: With a wide range of services, AWS 
allows you to choose the tools and technologies 
that best suit your needs. It's like having a toolbox 
By , Abhishek Shelar
with all the tools you need to build anything you 
want
• Global Reach: AWS has a global infrastructure, 
allowing you to reach customers all around the 
world with low latency.
 AWS Pricing Model
• Pay-As-You-Go: With this model, you pay only for 
the computing resources you consume, such as 
virtual servers (EC2 instances), storage (S3 
buckets), database usage (RDS), and data transfer 
(bandwidth). Prices are typically calculated based 
on usage hours, storage capacity, data transfer 
volume, etc.
• Reserved Instances: If you have predictable 
workloads, you can reserve instances for a oneyear or three-year term, which can provide 
significant discounts compared to the pay-as-yougo pricing.
• Spot Instances: These are spare computing 
resources available at discounted rates. You bid for 
these instances, and if your bid is higher than the 
• current spot price, you can use them. This model is 
suitable for workloads that can tolerate interruptions 
and have flexible start and end times.
• Dedicated Hosts: If you require compliance or 
regulatory requirements, you can lease dedicated 
By , Abhishek Shelar
physical servers (hosts) on AWS. Pricing is based 
on the host type and duration of the reservation.
• Free Tier: AWS offers a limited free tier for new 
customers, allowing them to explore and 
experiment with various services without incurring 
charges for a certain period.
• Usage-based Pricing: Some services have usagebased pricing, where you pay for the number of 
requests or operations performed, such as AWS 
Lambda (pay per invocation), Amazon DynamoDB 
(pay per provisioned throughput capacity and 
consumed read/write capacity), etc.
 Classification of AWS
• Compute Services: These services provide virtual 
servers, containers, and serverless computing 
options
• Example: Amazon EC2 (Elastic Compute Cloud) 
 AWS Lambda
 AWS Elastic Beanstalk
• Storage Services: These services help store and 
manage data in the cloud.
• Example: Amazon S3 (Simple Storage Service)
 Amazon EBS (Elastic Block Store)
By , Abhishek Shelar
 Amazon EFS (Elastic File System)
• Database Services: These services offer managed 
database solutions.
• Example: RDS (Relational Database Service) 
 Amazon DynamoDB
• Networking : Services for building and managing 
network infrastructure
• Example : Amazon VPC(Virtual Private Cloud)
 Amazon Route 53
 Amazon CloudFront
• Security,identity and Compliance : Services for 
securing and controlling access to AWS
resources,managing encryption and ensuring 
compliance with regulations.
• Example :AWS IAM(Identity & Access Mgmt)
 Relation between Regions and AZ 
Region : AWS divides the world into geographic 
regions,each containing multiple availability 
zones.These regions are seprate geographic 
areas,each with multiple data centers.
By , Abhishek Shelar
Availability Zones(AZ) : Within each region AWS 
has multiple availability zone typically consist of one 
or more data centers each with redundant 
power,networking and connectivity.
 Hypervisor
A hypervisor is a software that you can use to run 
multiple virtual machines on a single physical 
machine.Every virtual machine has its own 
operating system and applications.The hypervisor 
allocates the underlying physical computing 
resources such as CPU and memory to individual 
virtual machines as required.
Benefits of Hypervisor
• Hardware independence
• Efficiency
• Scalability
• Portability
Types of Hypervisor
Type 1:The type 1 hypervisor sits on top of the bare
metal server and has direct access to the hardware
resources.Because of this the type 1 hypervisor is also 
known as a bare metal hypervisor.
By , Abhishek Shelar
Type 2:The type 2 hypervisor is an application installed
on the host operating system.It’s also known as a 
hosted or embedded hypervisor.
 What is http & https ?
• HTTP (Hypertext Transfer Protocol) is a protocol 
used for transmitting data over the internet. It's like a 
language computers use to communicate with each 
other
• HTTPS (Hypertext Transfer Protocol Secure) is 
the secure version of HTTP. It encrypts the data 
being sent and received, making it much harder for 
hackers to intercept and read.
 EC2 (Elastic Compute Cloud)
• Amazon EC2 (Elastic Compute Cloud): Amazon 
EC2 provides resizable compute capacity in the 
cloud, allowing users to run virtual servers, known 
as instances. It's like renting a computer in the 
cloud that you can configure based on your needs. 
For instance, a software developer can use Amazon 
EC2 to deploy and run their application. They can 
choose the type of instance with specific computing 
power and memory requirements, scale up when 
By , Abhishek Shelar
demand increases, and shut down instances when 
not in use to save costs.
 Features of Amazon EC2 
 Instances
It is a Virtual servers.You can create and launch
many more virtual server as per there need.
Amazon Machine Images (AMIs)
Preconfigured templates for your instances that 
package the components you need for your server 
(including the operating system and additional 
software).
Instance types
Various configurations of CPU, memory, storage, 
networking capacity, and graphics hardware for 
your instances.
Key pairs
 Secure login information for your instances. AWS 
stores the public key and you store the private key in a 
secure place. Public key that is used for encrypt data 
and private key is used for decrypt data.
Instance store volumes
By , Abhishek Shelar
Storage volumes for temporary data that is 
deleted when you stop, hibernate, or terminate 
your instance.
Amazon EBS volumes
Persistent storage volumes for your data using 
Amazon Elastic Block Store (Amazon EBS).
Security groups
 In AWS a security group acts as a virtual firewall for 
your EC2 instances to control inbound and outbound 
traffic.It allows you to specify rules that govern which 
traffic is allowed to reach your instances and which 
traffic is blocked.
• Inbound rules control the incoming traffic, allowing 
or blocking specific types of data from entering a 
system or network.
• Outbound rules manage the outgoing traffic, 
determining what data can leave a system or 
network and where it can go.
Elastic IP addresses
Static IPv4 addresses for dynamic cloud computing
Virtual Private Cloud
 Virtual networks you can create that are logically 
isolated from the rest of the AWS Cloud.You can 
optionally connect these virtual networks to your own 
network.
By , Abhishek Shelar
 Types of Amazon EC-2 
• General Purpose Instances: These instances 
provide a balance of compute, memory, and 
networking resources. They are suitable for a wide 
range of applications, including web servers, small 
databases, and development environments.
• Compute Optimized Instances: These instances 
are designed for applications that require highperformance computing power. They are ideal for 
compute-bound applications such as batch 
processing, media transcoding, and highperformance web servers.
• Memory Optimized Instances: These instances 
are optimized for applications that require a lot of 
memory. They are suitable for memory-intensive 
applications such as in-memory databases, realtime big data analytics, and high-performance 
computing.
• Storage Optimized Instances: These instances 
are designed for applications that require high 
storage performance. They are ideal for 
applications that require high I/O performance, such 
as data warehousing, NoSQL databases, and 
Elasticsearch.
By , Abhishek Shelar
 Autoscaling
• Autoscaling in AWS means your website or 
application automatically adjusts the number of 
servers it's using based on how much traffic it's 
getting.
• Autoscaling in AWS allows you to configure and 
automatically provision and launch new instances
as per there need whenever the demand is 
increases.
Overview
• Autoscaling in AWS allows automatic scaling of 
compute resources based on demand.
• Ensures applications maintain optimal performance 
and cost-efficiency.
Key Concepts
1. Auto Scaling Group (ASG)
o Collection of EC2 instances treated as a logical 
group for scaling and management.
o Ensures a specified number of instances are 
running at all times.
o Automatically adds or removes instances 
based on defined policies.
2. Launch Configuration / Launch Template
o Specifies the instance configuration information 
for the instances in an ASG.
By , Abhishek Shelar
o Includes details such as the Amazon Machine 
Image (AMI), instance type, key pair, security 
groups, and block device mappings.
o Launch Templates offer more features and 
flexibility than Launch Configurations.
3. Scaling Policies
o Rules that determine when and how to scale 
the number of instances in an ASG.
o Dynamic Scaling: Adjusts capacity based on 
changing demand patterns.
▪ Target Tracking: Adjusts the number of 
instances to maintain a target value for a 
specific metric (e.g., CPU utilization).
▪ Simple Scaling: Adds or removes 
instances based on a single metric 
threshold.
▪ Step Scaling: Similar to simple scaling but 
with different actions based on the size of 
the metric deviation.
o Predictive Scaling: Uses machine learning to 
forecast future traffic and scales accordingly.
4. Scheduled Scaling
o Allows scaling actions to be scheduled at 
specific times or recurring intervals.
o Useful for predictable traffic patterns (e.g., daily 
traffic spikes).
5. Health Checks
o Ensures instances are functioning properly.
o If an instance fails health checks, it is 
terminated and replaced automatically.
By , Abhishek Shelar
o Can be based on EC2 status checks or custom 
health checks using Elastic Load Balancing 
(ELB).
 Load Balancer
• A load balancer distributes workloads across 
multiple compute resources, such as virtual servers. 
Using a load balancer increases the availability and 
fault tolerance of your applications.
• You can add and remove compute resources from 
your load balancer as your needs change, without 
disrupting the overall flow of requests to your 
applications.
• You can configure health checks, which monitor the 
health of the compute resources, so that the load 
balancer sends requests only to the healthy ones. 
You can also offload the work of encryption and 
decryption to your load balancer so that your 
compute resources can focus on their main work.
 Types of loadbalancer
1)Application Load Balancer (ALB): ALB 
operates at the application layer and is ideal for 
balancing HTTP and HTTPS traffic. It can route 
requests based on content, such as URL path or 
By , Abhishek Shelar
host, making it suitable for modern application 
architectures.
2)Network Load Balancer (NLB): NLB operates at 
the transport layer (Layer 4) and efficiently handles 
TCP and UDP traffic. It's designed to handle high 
volumes of traffic and supports static IP addresses 
and preservation of the client's source IP address.
3)Classic Load Balancer (CLB): CLB is the older 
generation load balancer in AWS, providing basic 
load balancing across multiple EC2 instances. It's 
suitable for simple applications not requiring 
advanced routing features.
4)Gateway Load Balancer(GLB): The Gateway 
Load Balancer(GWLB) is a regional,managed 
provided by AWS that allows you to deploy,scale
and manage third-party virtual appliances such as
firewalls,intrusion detection and prevention system 
and other security and networking appliances in the 
cloud.
 EBS
• AWS EBS is also called AWS Elastic Block Store.
• EBS is a service provided by AWS.
• EBS is provides persistent block-level storage 
volumes that can be attached to EC2 instances 
By , Abhishek Shelar
offering durable and high performance storage for 
various use cases.
• EBS volumes are used for data that needs to persist.
• It is important to backup the data with AWS EBS 
snapshots.
 Snapshot
EBS snapshot allow you to create backup of your EBS 
volumes at a specific point in time.This enables you to 
store the volumes to its state at that time,providing 
protection against data loss or corruption.
 EFS
• Amazon Elastic File System (Amazon EFS) provides 
serverless, fully elastic file storage so that you can 
share file data without provisioning or managing 
storage capacity and performance. Amazon EFS is 
built to scale on demand to petabytes without 
disrupting applications, growing and shrinking 
automatically as you add and remove files.
• Amazon EFS supports the Network File System 
version 4
• Amazon EFS supports authentication, authorization, 
and encryption capabilities to help you meet your 
security and compliance requirements.
By , Abhishek Shelar
 Amazon S3
• Amazon Simple Storage Service(Amazon S3)is an 
object service offered by Amazon Web 
Services(AWS).
• It is a designed to store and retrive any amount of 
data from anywhere on the web making it highly 
scalable reliable,and cost-effective.
• In amazon S3 we can create maximum 100 
buckets.
 Features of Amazon S3
Object Storage: Amazon S3 stores data as objects
within buckets.An object consist of data a key (unique 
identifier) and metadata.You can store virtually any type 
of data including images,videos,documents,backup,log 
files and application data.
Durability and Availability: S3 is designed for 
99.9999% durability meaning that your data is highly 
resilient and unlikely to be lost.
Scalability: Amazon S3 scales seamlessly to 
accommodate any amount of data.You can store 
By , Abhishek Shelar
virtually unlimited amounts of data in S3 without 
worrying about capacity constraints.
Security: S3 offers several features to help you protect
your data,including server-side encryption ,access 
control list bucket policies and IAM policies.
Amazon S3 Storage Classes
Amazon S3 offers various storage classes designed to 
address different data storage needs, providing flexibility 
in terms of cost, performance, and durability. Here are 
the primary S3 storage classes:
1. S3 Standard
• Description: General-purpose storage for 
frequently accessed data.
By , Abhishek Shelar
• Use Case: Suitable for a wide variety of use cases 
such as cloud applications, dynamic websites, 
content distribution, and big data analytics.
• Durability: 99.999999999% (11 nines).
• Availability: 99.99%.
• Features: Low latency and high throughput 
performance.
2. S3 Intelligent-Tiering
• Description: Optimizes costs by automatically 
moving data between two access tiers (frequent 
and infrequent) when access patterns change.
• Use Case: Ideal for data with unknown or changing 
access patterns.
• Durability: 99.999999999%.
• Availability: 99.9% over a given year.
• Features: Monitoring and automation charge for 
moving objects between access tiers.
3. S3 Standard-IA (Infrequent Access)
• Description: For data that is accessed less 
frequently but requires rapid access when needed.
• Use Case: Suitable for long-term storage, backups, 
and disaster recovery files.
• Durability: 99.999999999%.
• Availability: 99.9%.
• Features: Lower storage cost than S3 Standard but 
higher retrieval costs.
By , Abhishek Shelar
4. S3 One Zone-IA
• Description: For infrequently accessed data that 
does not require multiple availability zone resilience.
• Use Case: Ideal for cost-sensitive use cases such 
as secondary backups or easily re-creatable data.
• Durability: 99.999999999%.
• Availability: 99.5%.
• Features: Lower cost due to storage in a single 
availability zone.
5. S3 Glacier
• Description: Low-cost storage for data archiving 
where retrieval times of minutes to hours are 
acceptable.
• Use Case: Suitable for long-term data archiving, 
compliance, and digital preservation.
• Durability: 99.999999999%.
• Retrieval Options:
o Expedited: 1-5 minutes.
o Standard: 3-5 hours.
o Bulk: 5-12 hours.
• Features: Very low storage cost, with retrieval costs 
and varying retrieval times.
6. S3 Glacier Deep Archive
• Description: Lowest-cost storage class for longterm data archiving with retrieval times within 12 
hours.
By , Abhishek Shelar
• Use Case: Ideal for long-term digital preservation, 
regulatory archives, and backup data with rare 
access.
• Durability: 99.999999999%.
• Retrieval Options:
o Standard: 12 hours.
o Bulk: 48 hours.
• Features: Extremely low storage cost, suitable for 
data that can tolerate longer retrieval times.
By , Abhishek Shelar
Versioning
Versioning in Amazon S3 is a means of keeping multiple 
variants of an object in the same bucket.
You can use the S3 Versioning feature to preserve, 
retrieve, and restore every version of every object stored 
in your buckets. With versioning you can recover more 
easily from both unintended user actions and application 
failures. After versioning is enabled for a bucket, if 
By , Abhishek Shelar
Amazon S3 receives multiple write requests for the same 
object simultaneously, it stores all of those objects.
S3 storage Adding Process
Cross-Region Replication (CRR) in 
Amazon S3
Cross-Region Replication (CRR) is a feature in Amazon 
S3 that automatically replicates objects from a bucket in 
one AWS region to a bucket in another region. This 
enhances data availability, durability, and compliance 
with regulatory requirements.
By , Abhishek Shelar
AWS Snow Family: Snowball, 
Snowball Edge, and Snowmobile
The AWS Snow Family, comprising Snowball, Snowball 
Edge, and Snowmobile, provides physical devices to 
transfer large amounts of data into and out of AWS. 
These services help address challenges related to data 
transfer speed, security, and network connectivity.
AWS Snowball
Overview:
• AWS Snowball is a petabyte-scale data transport 
solution that uses secure devices to transfer large 
amounts of data to and from AWS.
• Purpose: Designed to move data to AWS quickly 
and securely, bypassing internet transfer 
bottlenecks.
Key Features:
• Storage Capacity: Available in 50 TB and 80 TB 
models.
• Security: Data is encrypted with 256-bit encryption 
keys managed through AWS Key Management 
Service (KMS). The device has a tamper-resistant 
design.
By , Abhishek Shelar
• Data Transfer Speed: Much faster than transferring 
over the internet, particularly useful for large 
datasets.
• Durability: Rugged and designed to withstand 
harsh environments.
Use Cases:
• Data migration to the cloud.
• Backup and disaster recovery.
• Data center decommissioning.
• Content distribution and collection.
Process:
1. Request Device: Order a Snowball device from the 
AWS Management Console.
2. Load Data: Connect the Snowball to your local 
network and use the Snowball client to transfer data 
onto the device.
3. Ship Back: Ship the Snowball back to AWS using 
the included shipping labels.
4. Import Data: AWS imports the data into your 
specified S3 bucket.
AWS Snowball Edge
Overview:
• AWS Snowball Edge is a more advanced version 
of Snowball, with additional compute capabilities.
• Purpose: Offers both data transfer and local 
processing capabilities.
Key Features:
By , Abhishek Shelar
• Storage Capacity: Available in 100 TB models.
• Compute Options: Comes in two configurations:
o Storage Optimized: Includes more storage 
capacity, suitable for large data transfers and 
storage-intensive applications.
o Compute Optimized: Includes more 
computing power, suitable for edge computing 
workloads.
• Local Processing: Allows running EC2 instances 
and Lambda functions directly on the device.
• Security: Data encryption and tamper-resistant 
design similar to Snowball.
Use Cases:
• Edge computing and IoT.
• Machine learning data preprocessing.
• Data collection in remote locations.
• Temporary storage expansion.
Process:
1. Request Device: Order a Snowball Edge device 
from the AWS Management Console.
2. Configure Compute: Deploy EC2 instances or 
Lambda functions if needed.
3. Load Data: Transfer data using the Snowball client 
or via AWS OpsHub.
4. Ship Back: Return the device to AWS.
5. Import Data: AWS imports the data into your 
specified S3 bucket.
By , Abhishek Shelar
AWS Snowmobile
Overview:
• AWS Snowmobile is an exabyte-scale data 
transfer service using a 45-foot-long ruggedized 
shipping container to move extremely large 
datasets to AWS.
• Purpose: Ideal for transferring up to 100 PB of 
data, typically for large-scale data center 
migrations.
Key Features:
• Storage Capacity: Up to 100 PB per Snowmobile.
• Security: Highly secure, with 256-bit encryption, 
GPS tracking, and 24/7 video surveillance during 
transport.
• Data Transfer Speed: Significantly faster than 
internet transfers for exabyte-scale data.
Use Cases:
• Large-scale data center migrations.
• Archival of massive datasets.
• High-resolution media content migration.
Process:
1. Engage with AWS: Work with AWS to plan and 
schedule the Snowmobile deployment.
2. Connect and Load Data: AWS delivers the 
Snowmobile to your data center. Connect it to your 
network and transfer data using high-speed network 
connections.
By , Abhishek Shelar
3. Transport and Import: The Snowmobile is 
transported back to AWS, where the data is 
securely imported into your specified S3 buckets.
Identity Access Management (IAM)
Identity Access Management (IAM)
AWS Identity and Access Management (IAM) is a web 
service that helps you securely control access to AWS 
services and resources. It allows you to manage users, 
groups, roles, and permissions to ensure that only 
authorized individuals and processes can access your 
resources.
Key Concepts
1. Users
o Represents an individual or service that interacts with 
AWS.
o Each user has a unique name and can have its own 
credentials (password and access keys).
2. Groups
o A collection of IAM users.
o Allows you to manage permissions for multiple users 
simultaneously.
o Users in a group inherit permissions assigned to the 
group.
3. Roles
o An IAM role is similar to a user but intended to be 
assumable by anyone who needs it.
o Useful for granting temporary access to AWS 
resources.
o Roles are often used for cross-account access or for 
AWS services to perform tasks on your behalf.
By , Abhishek Shelar
4. Policies
o Documents that define permissions.
o JSON format, specifying actions allowed or denied.
o Can be attached to users, groups, and roles.
o Types of policies include managed policies (AWSmanaged and customer-managed) and inline 
policies.
o
5. Permissions
o Specifies what actions are allowed or denied.
o Can be fine-grained to specify which resources can 
be accessed and under what conditions.
o
6. Access Keys
o Consist of an access key ID and a secret access key.
o Used for programmatic access via the AWS CLI, 
SDKs, or APIs.
o
7. Multi-Factor Authentication (MFA)
o Adds an extra layer of security by requiring a second 
form of authentication.
o Supported via virtual MFA devices, hardware MFA 
devices, or SMS.
Best Practices
1. Principle of Least Privilege
o Grant only the permissions necessary for users to 
perform their tasks.
o Regularly review and adjust permissions.
o
2. Use IAM Roles for Applications
o Instead of embedding access keys in applications, 
use IAM roles to grant permissions securely.
o
3. Enable MFA for Privileged Users
o Protect sensitive accounts and users with MFA.
By , Abhishek Shelar
o
4. Regularly Rotate Credentials
o Regularly change passwords and access keys to 
reduce the risk of compromise.
o
5. Monitor and Audit IAM Activity
o Use AWS CloudTrail to log and monitor IAM 
activities.
o Regularly review logs to detect any unauthorized 
access or anomalies.
Example Use Cases
1. User Management
o Create IAM users for each individual needing access 
to AWS.
o Assign permissions through groups or individual 
policies.
o
2. Service Roles
o Create roles for AWS services like EC2, Lambda, or 
ECS, allowing these services to interact with other 
AWS resources securely.
o
3. Cross-Account Access
o Use IAM roles to grant access to resources in 
different AWS accounts without sharing long-term 
credentials.
o
4. Temporary Security Credentials
o Use IAM roles in conjunction with AWS STS (Security 
Token Service) to grant temporary access to 
resources.
o
By , Abhishek Shelar
Steps to Get Started with IAM
1. Create an IAM User
o Go to the IAM dashboard in the AWS Management 
Console.
o Create a new user and assign permissions directly or 
through a group.
o
2. Set Up Groups and Assign Permissions
o Create groups based on job functions (e.g., Admins, 
Developers).
o Attach appropriate policies to each group.
o Add users to the respective groups.
o
3. Create and Attach Policies
o Define policies in JSON format specifying required 
permissions.
o Attach policies to users, groups, or roles.
o
4. Enable MFA for Users
o Set up MFA devices for users with sensitive access.
o
5. Create IAM Roles
o Define roles with necessary permissions for AWS 
services or cross-account access.
o Assign roles to services or users as needed.
Amazon Simple Notification Service 
(SNS)
Overview:
• Purpose: SNS is a managed messaging service for 
sending notifications to multiple subscribers.
By , Abhishek Shelar
• Use Cases: Message delivery to emails, SMS, mobile 
push notifications, HTTP endpoints, AWS Lambda, and 
SQS.
Key Concepts:
• Topics: Points for message distribution.
• Subscribers: Endpoints receiving messages (HTTP, 
email, SMS, etc.).
• Messages: Data sent to subscribers.
Features:
• Message Filtering: Subscribers receive only relevant 
messages.
• Fan-out Pattern: Distribute messages to multiple SQS 
queues.
• Access Control: Policies for publishing and subscribing.
• Durability: Message storage across availability zones.
Common Commands:
• Create Topic: aws sns create-topic --name my-topic
• Subscribe: aws sns subscribe --topic-arn <topic-arn> --
protocol email --notification-endpoint <email>
• Publish: aws sns publish --topic-arn <topic-arn> --
message "Hello World"
Amazon Simple Queue Service 
(SQS)
Overview:
• Purpose: SQS is a managed message queuing service 
for decoupling components.
• Use Cases: Decoupling applications, buffering operations, 
asynchronous workflows.
By , Abhishek Shelar
Key Concepts:
• Queues: Standard (best-effort ordering) and FIFO 
(exactly-once processing).
• Messages: Data in the queue, up to 256 KB.
• Producers: Send messages.
• Consumers: Receive and process messages.
Features:
• Message Visibility Timeout: Temporary message 
invisibility after reading.
• Dead-Letter Queues: Handle unprocessable messages.
• Message Retention: 1 minute to 14 days.
• Delayed Delivery: Postpone messages up to 15 minutes.
Common Commands:
• Create Queue: aws sqs create-queue --queue-name myqueue
• Send Message: aws sqs send-message --queue-url 
<queue-url> --message-body "Hello World"
• Receive Message: aws sqs receive-message --queue-url 
<queue-url>
• Delete Message: aws sqs delete-message --queue-url 
<queue-url> --receipt-handle <receipt-handle>
Integration Between SNS and SQS
Setup:
1. Create SNS Topic
2. Create SQS Queue
3. Subscribe SQS Queue to SNS Topic
4. Process Messages from SQS Queue
By , Abhishek Shelar
Amazon Elastic File System (EFS)
Overview:
• Purpose: Amazon EFS is a scalable, fully managed file 
storage service for use with AWS Cloud services and onpremises resources.
• Use Cases: Shared file storage for EC2 instances, big 
data and analytics, content management, web serving, 
and home directories.
Key Features:
• Scalability: Automatically scales up and down as you add 
or remove files.
•
• Elasticity: No need to provision or manage capacity. It 
grows and shrinks as you add or remove files.
•
• Performance Modes: Offers General Purpose (default) 
and Max I/O for applications that require high throughput.
•
• Storage Classes: Standard and Infrequent Access (IA) to 
optimize cost.
•
By , Abhishek Shelar
• Access Control: Supports AWS Identity and Access 
Management (IAM), Network File System (NFS) v4.0 and 
v4.1 protocols.
•
Benefits:
• Managed Service: Fully managed by AWS, reducing 
administrative overhead.
• High Availability: Data is stored across multiple 
Availability Zones (AZs) for redundancy.
• Security: Supports encryption at rest and in transit, along 
with VPC integration for network-level security.
Common Commands:
• Create File System: aws efs create-file-system --creationtoken MyEFS
• Create Mount Target: aws efs create-mount-target --filesystem-id <fs-id> --subnet-id <subnet-id>
• Describe File Systems: aws efs describe-file-systems
• Delete File System: aws efs delete-file-system --filesystem-id <fs-id>
Network File System (NFS) in AWS
Overview:
• Purpose: NFS is a distributed file system protocol that 
allows access to files over a network similar to local 
storage.
• Use Cases: Shared file storage for EC2 instances, data 
sharing across multiple systems, and centralized storage 
management.
By , Abhishek Shelar
Amazon RDS (Relational Database 
Service
What is Amazon RDS?
Amazon RDS is a managed relational database service that 
simplifies setting up, operating, and scaling a relational 
database in the cloud. It provides cost-efficient and resizable 
capacity while managing time-consuming database 
administration tasks, freeing up resources to focus on your 
applications and business.
Supported Database Engines
Amazon RDS supports several database engines:
• Amazon Aurora (compatible with MySQL and 
PostgreSQL)
• MySQL
• MariaDB
• PostgreSQL
• Oracle
• Microsoft SQL Server
Key Features
• Automated Backups: Automatic backup of your DB 
instance during the backup window you specify, plus the 
ability to create DB snapshots.
•
• Database Monitoring and Metrics: Detailed monitoring 
and metrics collection with Amazon CloudWatch.
•
• Security: Data encryption at rest and in transit using AWS 
Key Management Service (KMS).
•
By , Abhishek Shelar
• Scaling: Vertical scaling (changing instance types) and 
horizontal scaling (adding read replicas).
•
• Automatic Software Patching: Automatic patching of the 
database engine software.
•
• Multi-AZ Deployments: Provides enhanced availability 
and durability by automatically replicating the database to 
a standby instance in a different Availability Zone.
•
• Read Replicas: Support for read-heavy database 
workloads by allowing read traffic to be offloaded to read 
replicas.
Cost Considerations
• Instance Types: Different types of instances with varying 
pricing based on performance and capabilities.
•
• Storage: Costs depend on the type (SSD, Provisioned 
IOPS) and amount of storage.
•
• Backup Storage: Backup storage beyond the size of your 
database is charged.
• Data Transfer: Costs for data transferred out of AWS.
Use Cases
• Web and Mobile Applications: Backing web and mobile 
apps with a reliable and scalable relational database.
•
• E-commerce Applications: Managing transactionintensive e-commerce applications.
•
By , Abhishek Shelar
• Business Applications: Supporting enterprise 
applications such as ERP, CRM, and other business 
software.
•
• Data Warehousing: Using Amazon Aurora for highperformance data warehousing solutions.
•
Creating an RDS Instance
1. Sign in to AWS Management Console.
2. Navigate to RDS service.
3. Click "Create database."
4. Choose a database creation method: Standard Create 
or Easy Create.
5. Select a database engine: MySQL, PostgreSQL, 
MariaDB, Oracle, SQL Server, or Amazon Aurora.
6. Specify DB details: DB instance identifier, master 
username, and password.
7. Configure advanced settings: Network & Security, DB 
options, Backup, Monitoring, Maintenance, and Tags.
8. Review and create.
Best Practices
• Use Multi-AZ for high availability.
• Enable automated backups and snapshots.
• Monitor performance metrics and set up alerts.
• Regularly update the database engine to the latest 
version.
• Use the appropriate instance type and storage option 
based on workload requirements.
• Implement security best practices: VPC, security 
groups, encryption.
By , Abhishek Shelar
Amazon Route 53 
What is Amazon Route 53?
Amazon Route 53 is a scalable and highly available DNS and 
domain name registration service. It connects user requests to 
infrastructure running in AWS, such as EC2 instances, load 
balancers, and S3 buckets, and can also be used to route 
users to infrastructure outside of AWS.
Key Features of Route 53
• Domain Registration: Register domain names directly 
with Route 53.
• DNS Routing: Translate friendly domain names like
www.example.com into IP addresses like 192.0.2.1.
• Health Checking and Monitoring: Route 53 can monitor 
the health of your resources and reroute traffic if a 
resource becomes unavailable.
• Traffic Flow: Easy-to-use traffic policies to manage traffic 
globally through a visual editor.
• Latency-based Routing: Direct users to the AWS region 
that provides the lowest latency.
• Geo DNS: Route traffic based on the geographic location 
of users.
• Weighted Round Robin: Distribute traffic across multiple 
resources based on specified weights.
• Failover: Automatic failover to healthy resources in case 
of failure.
DNS Concepts in Route 53
1. Hosted Zones:
By , Abhishek Shelar
o A hosted zone is a container for records that define 
how to route traffic for a domain.
o Types:
▪ Public Hosted Zone: Routes traffic on the 
internet.
▪ Private Hosted Zone: Routes traffic within one 
or more VPCs.
2. DNS Records:
o A Record (Address Record): Maps a domain name 
to an IPv4 address.
o AAAA Record: Maps a domain name to an IPv6 
address.
o CNAME Record (Canonical Name Record): Maps 
a domain name to another domain name.
o MX Record (Mail Exchange Record): Directs email 
to a mail server.
o TXT Record: Provides text information to sources 
outside your domain.
o SRV Record: Specifies the location of servers for 
specific services.
o NS Record (Name Server Record): Indicates which 
DNS server is authoritative for the domain.
o SOA Record (Start of Authority Record): Provides 
information about the domain and the zone.
3. Routing Policies:
o Simple Routing: A single resource for a DNS name.
o Weighted Routing: Distribute traffic across multiple 
resources based on specified weights.
o Latency-based Routing: Route traffic to the region 
with the best latency.
By , Abhishek Shelar
o Failover Routing: Route traffic to a secondary 
resource if the primary one is unhealthy.
o Geolocation Routing: Route traffic based on the 
geographic location of the user.
o Geoproximity Routing (Traffic Flow only): Route 
traffic based on the geographic location of users and 
resources, and optionally, shift traffic from resources 
in one location to another.
o Multi-Value Answer Routing: Return multiple 
values, such as IP addresses, in response to DNS 
queries.
4. Health Checks:
o Endpoint Monitoring: Regularly check the health of 
your endpoints (e.g., web servers).
o Automatic DNS Failover: Automatically failover to 
healthy endpoints if an endpoint fails.
o Health Check Types:
▪ HTTP/HTTPS: Check the health of a web server 
by sending HTTP or HTTPS requests.
▪ TCP: Check the health by establishing a TCP 
connection.
▪ CloudWatch Alarms: Use CloudWatch alarms to 
monitor the status.
Domain Registration
• You can register new domain names directly through 
Route 53.
• Route 53 also supports transferring domains from other 
registrars.
• Domain registration includes automatic DNS setup with 
Route 53 as the DNS service.
By , Abhishek Shelar
Amazon CloudWatch 
What is Amazon CloudWatch?
Amazon CloudWatch is a monitoring and management service 
that provides data and actionable insights for AWS, hybrid, and 
on-premises applications and infrastructure resources. It helps 
you monitor and track the operational health, performance, and 
usage of your resources in real-time.
Key Features
1. Metrics Collection:
o System Metrics: Collects and tracks metrics for 
AWS services like EC2, RDS, DynamoDB, and more.
o Custom Metrics: Enables you to publish custom 
metrics from your applications and on-premises 
servers.
2. Logs Management:
o CloudWatch Logs: Collects, monitors, and stores 
log files from EC2 instances, AWS Lambda, and 
other sources. It allows you to search and filter logs, 
create metrics from log data, and set alarms.
o Log Insights: Provides a query language to extract 
insights from log data.
3. Alarms:
o Threshold-based Alarms: Set alarms to 
automatically react to metric thresholds or anomalies.
o Composite Alarms: Combine multiple alarms to 
reduce noise and provide more actionable alerts.
4. Dashboards:
o Custom Dashboards: Create and customize 
dashboards to visualize and correlate metrics, logs, 
and alarms.
o Widgets: Use various widgets to display data in 
graphs, numbers, and text formats.
By , Abhishek Shelar
5. Events:
o Event-driven Monitoring: Detect and respond to 
changes in your AWS resources with CloudWatch 
Events and EventBridge.
o Automated Responses: Trigger AWS Lambda 
functions, SNS notifications, or other automated 
actions based on events.
6. Application Insights:
o Automated Application Monitoring: Provides 
automatic detection of common problems in 
applications running on AWS and on-premises.
o Deep Insights: Delivers insights into application 
performance and dependencies.
Monitoring AWS Resources
CloudWatch provides built-in metrics for many AWS services, 
including:
• EC2: CPU utilization, disk I/O, network traffic, and more.
• RDS: CPU utilization, database connections, read/write 
IOPS, and more.
• ECS/EKS: Cluster, service, and task-level metrics.
• Lambda: Invocation count, duration, error count, and 
more.
• S3: Bucket size, number of objects, and request metrics.
Custom Metrics
You can publish custom metrics to CloudWatch using:
• AWS SDKs and APIs: Use AWS SDKs or APIs to publish 
application-specific metrics.
• CloudWatch Agent: Collects system-level metrics from 
on-premises servers and EC2 instances.
• Embedded Metric Format (EMF): A JSON-based format 
to log and visualize custom metrics.
By , Abhishek Shelar
CloudWatch Logs
• Log Groups and Streams: Organize log data into groups 
and streams.
• Subscription Filters: Stream log data to other services 
like Amazon Elasticsearch, AWS Lambda, or Kinesis Data 
Streams.
• Retention Policies: Set retention periods for log data to 
manage storage costs.
CloudWatch Alarms
• Standard Alarms: Trigger actions based on predefined 
thresholds for metric values.
• Composite Alarms: Combine multiple alarms to reduce 
noise and take complex actions.
• Alarm Actions: Send notifications via SNS, auto-scale 
EC2 instances, or trigger Lambda functions.
CloudWatch Dashboards
• Widgets: Add graphs, numbers, text, and other widgets to 
visualize metrics.
• Cross-account Dashboards: Create dashboards that 
aggregate data across multiple AWS accounts.
• Sharing Dashboards: Share dashboards within your 
AWS organization or publicly.
CloudWatch Events and EventBridge
• Event Sources: AWS services, custom applications, and 
SaaS partners.
• Event Rules: Define rules to match incoming events and 
route them to targets.
• Targets: Lambda functions, Step Functions, ECS tasks, 
SNS topics, SQS queues, and more.
By , Abhishek Shelar
Best Practices
• Set Up Alarms: Monitor critical metrics and set up alarms 
for proactive incident response.
• Use Dashboards: Create dashboards for different teams 
and use cases to get a holistic view of system health.
• Enable Logging: Enable detailed logging for AWS 
services to gain deeper insights and troubleshoot issues.
• Optimize Retention: Manage log and metric retention 
policies to balance cost and data availability.
• Leverage Insights: Use CloudWatch Logs Insights and 
Application Insights to diagnose and resolve performance 
issues quickly.
Amazon CloudTrai
What is Amazon CloudTrail?
Amazon CloudTrail is a service that records AWS API calls and 
delivers log files to an Amazon S3 bucket. The recorded 
information includes the identity of the API caller, the time of 
the API call, the source IP address of the API caller, the 
request parameters, and the response elements returned by 
the AWS service.
Key Features
1. Event History:
By , Abhishek Shelar
o Management Events: Logs API operations that 
create, modify, or delete resources in your AWS 
account.
o Data Events: Logs operations on or within resource 
types like Amazon S3 objects or AWS Lambda 
functions.
o Insight Events: Detects unusual operational activity 
in your account.
2. Trail Creation:
o Single Region Trail: Records events in a single 
region.
o Multi-Region Trail: Records events in all regions.
3. Event Delivery:
o S3 Bucket: Delivers log files to an S3 bucket of your 
choice.
o CloudWatch Logs: Optionally, you can configure 
CloudTrail to send events to CloudWatch Logs for 
real-time monitoring.
4. Security and Integrity:
o Log File Integrity Validation: Provides a way to 
verify the integrity and authenticity of your log files.
o Encryption: Supports server-side encryption with 
AWS KMS-managed keys.
5. Integration with AWS Services:
o Amazon Athena: Query CloudTrail logs directly from 
S3 using SQL.
o Amazon CloudWatch: Create alarms and 
dashboards based on CloudTrail events.
o AWS Config: Track configuration changes alongside 
API activity.
Key Concepts
1. Trails:
o A trail is a configuration that enables delivery of 
events to an S3 bucket and optionally to CloudWatch 
Logs.
By , Abhishek Shelar
o You can create multiple trails for different purposes, 
such as separating management events from data 
events.
2. Events:
o Management Events: Include operations like 
creating EC2 instances, IAM user modifications, etc.
o Data Events: Include resource operations like S3 
object-level API activity (GetObject, PutObject) or 
Lambda function invocations.
o Insight Events: Automatically analyzes write 
management events to detect unusual patterns of 
activity.
3. Event Selectors:
o Define which types of events are logged by a trail. 
You can configure separate event selectors for 
management and data events.
4. Logs and Monitoring:
o CloudTrail logs are delivered to an S3 bucket and 
can be monitored via CloudWatch Logs.
o Use Amazon Athena to run queries on CloudTrail 
logs stored in S3.
5. Cross-Account and Multi-Region Logging:
o CloudTrail supports logging across multiple AWS 
accounts and regions to provide a centralized audit 
trail.
Amazon VPC
What is Amazon VPC?
Amazon VPC lets you provision a logically isolated section of 
the AWS cloud where you can launch AWS resources in a 
By , Abhishek Shelar
virtual network that you define. You have complete control over 
your virtual networking environment, including selection of your 
own IP address range, creation of subnets, and configuration of 
route tables and network gateways.
Key Features
1. Subnets:
o Public Subnets: Subnets with a route to an internet 
gateway, allowing direct communication with the 
internet.
o Private Subnets: Subnets without a route to an 
internet gateway, used for resources that should not 
be directly accessible from the internet.
o Isolated Subnets: Subnets with no route to an 
internet gateway or a virtual private gateway, used for 
resources with no external connectivity.
2. Route Tables:
o Control the traffic routing within your VPC. You can 
create custom route tables to define traffic rules for 
subnets.
3. Internet Gateway (IGW):
o A horizontally scaled, redundant, and highly available 
VPC component that allows communication between 
instances in your VPC and the internet.
4. NAT Gateway:
o A managed service that enables instances in a 
private subnet to connect to the internet or other 
AWS services, but prevents the internet from 
initiating connections with those instances.
5. Virtual Private Gateway:
o Enables you to establish a VPN connection between 
your VPC and your on-premises network.
6. VPC Peering:
o Allows you to route traffic between VPCs using 
private IP addresses. VPCs can be in different AWS 
By , Abhishek Shelar
accounts or different regions (inter-region VPC 
peering).
7. Transit Gateway:
o A highly available and scalable service that enables 
you to connect multiple VPCs and on-premises 
networks through a single gateway.
8. Elastic IP Addresses:
o Static IP addresses designed for dynamic cloud 
computing. You can associate an Elastic IP address 
with any instance or network interface for quick 
failover.
9. Security Groups:
o Act as virtual firewalls for your instances to control 
inbound and outbound traffic.
10. Network ACLs (Access Control Lists):
o Optional layer of security for your VPC that acts as a 
stateless firewall for controlling traffic in and out of 
one or more subnets.
11. Flow Logs:
o Capture information about the IP traffic going to and 
from network interfaces in your VPC.
Key Concepts
1. CIDR Blocks:
o Classless Inter-Domain Routing blocks define the IP 
address range for your VPC (e.g., 10.0.0.0/16).
2. Subnets:
o Divide the VPC's IP address range into smaller 
segments to organize resources.
3. Route Tables:
o Direct network traffic within your VPC and to the 
internet or other networks.
4. Gateways and Endpoints:
o Manage connections to the internet, other VPCs, or 
on-premises networks
By , Abhishek Shelar
AWS Lambda
What is AWS Lambda?
AWS Lambda lets you run code in response to events without 
managing servers. It automatically scales your application by 
running code in response to triggers, and you pay only for the 
compute time consumed.
Key Features
1. Serverless Computing:
o With Lambda, you don't need to provision or manage 
servers. AWS handles server maintenance, capacity 
provisioning, scaling, and security patches.
2. Event-Driven Programming:
o Lambda allows you to trigger code execution in 
response to various events from AWS services or 
custom applications.
3. Wide Range of Triggers:
o Lambda can be triggered by events from many AWS 
services, including S3, DynamoDB, SQS, SNS, 
CloudWatch Events, and API Gateway.
4. Supported Runtimes:
o Lambda supports multiple programming languages, 
including Node.js, Python, Java, Go, Ruby, and .NET 
Core.
5. Scalability:
o Lambda automatically scales your application by 
running code in parallel in response to each trigger.
6. Integrated Security:
o Lambda integrates with AWS Identity and Access 
Management (IAM) for fine-grained access control 
By , Abhishek Shelar
and AWS Key Management Service (KMS) for 
encryption of environment variables.
Key Concepts
1. Lambda Function:
o A Lambda function is a piece of code that runs in 
response to events. It consists of code written in a 
supported language and associated configuration 
information.
2. Trigger:
o A trigger is an event that invokes a Lambda function. 
Triggers can be from AWS services, such as S3, 
DynamoDB, SQS, or custom sources via API 
Gateway or CloudWatch Events.
3. Invocation:
o An invocation is the act of invoking a Lambda 
function. Invocations can be synchronous (e.g., API 
Gateway) or asynchronous (e.g., S3 events).
4. Concurrency:
o Concurrency refers to the number of function 
instances that can run simultaneously. Lambda 
automatically scales the concurrency based on 
incoming requests.
5. Execution Environment:
o Lambda provides a runtime environment for 
executing functions. You can configure memory, 
timeout, and other settings for the execution 
environment.
6. Integration with Other AWS Services:
o Lambda integrates seamlessly with other AWS 
services, allowing you to build serverless applications 
that respond to events from various sources.
Example :
By , Abhishek Shelar
To use Lambda to stop and start EC2 instances at regular 
intervals, complete the following steps:
1. Create a custom AWS Identity and Access Management 
(IAM) policy and IAM role for your Lambda function.
2. Create Lambda functions that stop and start your EC2 
instances.
3. Test your Lambda functions.
4. Create EventBridge schedules that run your function on a 
schedule.
Note: You can also create rules that react to events in 
your AWS account.
Resolution
Note: After you complete the following steps, you might receive 
a Client error on launch error. For more information, 
see When I start my instance with encrypted volumes attached, 
the instance immediately stops with the error "client error on 
launch."
Get the IDs of the EC2 instances that you want to stop and 
start. Then, complete the following steps.
Create an IAM policy and IAM role for your Lambda 
function
1. Use the JSON policy editor to create an IAM policy. Paste 
the following JSON policy document into the policy editor:
2. { "Version": "2012-10-17",
3. "Statement": [
4. {
5. "Effect": "Allow",
6. "Action": [
7. "logs:CreateLogGroup",
8. "logs:CreateLogStream",
By , Abhishek Shelar
9. "logs:PutLogEvents"
10. ],
11. "Resource": "arn:aws:logs:*:*:*"
12. },
13. {
14. "Effect": "Allow",
15. "Action": [
16. "ec2:Start*",
17. "ec2:Stop*"
18. ],
19. "Resource": "*"
20. }
21. ]
}
22. Create an IAM role for Lambda.
Important: When you attach a permissions policy to 
Lambda, make sure that you choose the IAM policy.
Note: If you use an Amazon Elastic Block Store (Amazon EBS) 
volume that's encrypted by a customer-managed AWS Key 
Management Service (AWS KMS) key, then 
add kms:CreateGrant to the IAM policy.
Create Lambda functions that stop and start your 
instances
1. Open the Lambda console, and then choose Create 
function.
2. Choose Author from scratch.
3. Under Basic information, enter the following information:
For Function name, enter a name that describes the 
function, such as "StopEC2Instances".
For Runtime, choose Python 3.9.
Under Permissions, expand Change default execution 
role.
Under Execution role, choose Use an existing role.
Under Existing role, choose the IAM role.
By , Abhishek Shelar
4. Choose Create function.
5. On the Code tab, under Code source, paste the following 
code into the editor pane of the code editor on 
the lambda_function tab. This code stops the instances 
that you identify:
6. import boto3
7. region = 'us-west-1'
8. instances = ['i-12345cb6de4f78g9h', 'i08ce9b2d7eccf6d26']
9. ec2 = boto3.client('ec2', region_name=region)
10.
11. def lambda_handler(event, context):
12. ec2.stop_instances(InstanceIds=instances)
 print('stopped your instances: ' + str(instances))
Replace us-west-1 with the AWS Region that your 
instances are in. Replace InstanceIds with the IDs of the 
instances that you want to stop and start.
13. Choose Deploy.
14. On the Configuration tab, choose General 
configuration, and then choose Edit.
15. Set Timeout to 10 seconds, and then choose Save.
Note: (Optional) You can adjust the Lambda function 
settings. For example, to stop and start multiple instances, 
you might use a different value for Timeout and Memory.
